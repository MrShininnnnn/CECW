{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorful Extended Cleanup World (CECW)\n",
    "The Colorful Extended Cleanup World (CECW) dataset is a color-extended version of the Cleanup World (CW) borrowed from the mobile-manipulation robot domain [(MacGlashan et al., 2015)](http://cs.brown.edu/~jmacglashan/pubpdfs/rss_commands.pdf). CW refers to a world equipped with a movable object as well as four rooms in four colors, including \"blue,\" \"green,\" \"red,\" and \"yellow,\" which is designed as a simulation environment where the agent can act based on the instructions received [(Gopalan et al., 2018)](http://roboticsproceedings.org/rss14/p67.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction, Cleaning, and Splitting\n",
    "This notebook shows how we format CW to our CECW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path definition\n",
    "# credits to MacGlashan et al., 2015 and Gopalan et al., 2018\n",
    "# more info here - https://github.com/jmacglashan/commandsToTasks\n",
    "RAW_SRC_PATH = 'CW/hard_pc_src_syn.txt' # input source data\n",
    "RAW_TAR_PATH = 'CW/hard_pc_tar_syn.txt' # input target data\n",
    "\n",
    "TRAIN_SRC_PATH = 'train_src.txt' # output training source data\n",
    "TRAIN_TAR_PATH = 'train_tar.txt' # output training target data\n",
    "TEST_SRC_PATH = 'test_src.txt' # output test source data\n",
    "TEST_TAR_PATH = 'test_tar.txt' # output test target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data size: 3382\n"
     ]
    }
   ],
   "source": [
    "raw_src_list = read_txt(RAW_SRC_PATH) # input source data list\n",
    "raw_tar_list = read_txt(RAW_TAR_PATH) # input target data list\n",
    "# 3382 commands reflecting a total of 39 GLTL expressions\n",
    "raw_data_size = len(raw_src_list)\n",
    "print('raw data size:', raw_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinds of commands 2130\n",
      "kinds of expressions 39\n"
     ]
    }
   ],
   "source": [
    "print('kinds of commands', len(set(raw_src_list)))\n",
    "print('kinds of expressions', len(set(raw_tar_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command: go through the yellow or green room to reach the blue room\n",
      "expression: F & | C Y F B\n"
     ]
    }
   ],
   "source": [
    "# take a look\n",
    "index = random.choice(range(raw_data_size))\n",
    "print('command:', raw_src_list[index])\n",
    "print('expression:', raw_tar_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source vocab size: 188\n",
      "source vocab frequency\n",
      "[('the', 5236), ('room', 5224), ('to', 3476), ('go', 2243), ('blue', 1744), ('green', 1708), ('red', 1529), ('yellow', 1387), ('through', 1275), ('move', 846), ('and', 486), ('into', 474), ('get', 411), ('enter', 342), ('or', 321), ('then', 320), ('not', 264), ('avoiding', 244), ('but', 243), ('that', 180), ('without', 170), ('avoid', 159), ('while', 155), ('area', 145), ('by', 142), ('reach', 138), ('t', 125), ('going', 123), ('chair', 123), ('rooms', 101), ('only', 100), ('do', 100), ('a', 98), ('robot', 95), ('is', 90), ('entering', 84), ('large', 83), ('box', 78), ('push', 78), ('pass', 77), ('via', 75), ('from', 75), ('isn', 75), ('pink', 68), ('towards', 65), ('travel', 65), ('small', 63), ('in', 58), ('way', 55), ('first', 52), ('you', 51), ('don', 50), ('on', 48), ('square', 45), ('using', 44), ('either', 44), ('up', 41), ('passing', 40), ('one', 39), ('proceed', 38), ('object', 37), ('it', 36), ('walk', 35), ('door', 31), ('of', 31), ('back', 31), ('path', 30), ('take', 30), ('which', 30), ('rectangular', 30), ('any', 30), ('rectangle', 29), ('are', 29), ('there', 27), ('thru', 26), ('goes', 25), ('your', 24), ('until', 23), ('follow', 20), ('navigate', 20), ('colour', 20), ('avoids', 20), ('non', 20), ('use', 20), ('exit', 19), ('continue', 19), ('end', 19), ('toward', 18), ('other', 16), ('make', 15), ('crossing', 15), ('drive', 15), ('purple', 15), ('stop', 14), ('must', 14), ('head', 14), ('straight', 14), ('has', 13), ('bring', 13), ('when', 10), ('moves', 10), ('sure', 10), ('place', 10), ('taking', 10), ('black', 10), ('at', 10), ('will', 10), ('lead', 10), ('except', 10), ('if', 9), ('away', 9), ('find', 8), ('over', 6), ('color', 6), ('leave', 6), ('keep', 5), ('rectanglular', 5), ('leads', 5), ('please', 5), ('always', 5), ('instead', 5), ('cross', 5), ('being', 5), ('moving', 5), ('ends', 5), ('before', 5), ('throught', 5), ('gain', 5), ('access', 5), ('rom', 5), ('all', 5), ('white', 5), ('though', 5), ('progress', 5), ('out', 5), ('hallway', 5), ('takes', 5), ('each', 5), ('time', 5), ('totally', 5), ('behind', 5), ('pick', 5), ('big', 5), ('c', 5), ('this', 5), ('took', 5), ('shortest', 5), ('route', 5), ('opposite', 5), ('got', 5), ('never', 5), ('stepping', 5), ('spaces', 5), ('once', 5), ('isnt', 5), ('item', 5), ('proceeding', 5), ('side', 5), ('stay', 4), ('after', 4), ('i', 4), ('want', 4), ('passage', 4), ('middle', 4), ('right', 4), ('them', 4), ('thing', 4), ('retrieve', 2), ('grab', 2), ('come', 2), ('return', 2), ('far', 2), ('wall', 2), ('orange', 2), ('with', 2), ('front', 1), ('left', 1), ('violet', 1), ('carry', 1), ('backto', 1), ('dog', 1), ('down', 1), ('across', 1), ('backpack', 1), ('below', 1), ('locate', 1), ('under', 1), ('goto', 1)]\n"
     ]
    }
   ],
   "source": [
    "# sum up tokens from source side\n",
    "src_counter = Counter()\n",
    "for src in raw_src_list:\n",
    "    src_counter.update(src.split())\n",
    "src_token_freq_dict = dict(src_counter)\n",
    "print('source vocab size:', len(src_token_freq_dict))\n",
    "print('source vocab frequency')\n",
    "print(src_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target vocab size: 11\n",
      "target vocab frequency\n",
      "[('F', 4962), ('&', 2585), ('C', 1648), ('B', 1616), ('R', 1537), ('Y', 1329), ('G', 1005), ('!', 1005), ('|', 319), ('X', 99), ('Z', 57)]\n"
     ]
    }
   ],
   "source": [
    "# sum up tokens from target side\n",
    "tar_counter = Counter()\n",
    "for tar in raw_tar_list:\n",
    "    tar_counter.update(tar.split())\n",
    "tar_token_freq_dict = dict(tar_counter)\n",
    "print('target vocab size:', len(tar_token_freq_dict))\n",
    "print('target vocab frequency')\n",
    "print(tar_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color words to each entity\n",
    "# primitive rules:\n",
    "# blue -> B\n",
    "# green -> C\n",
    "# red -> R\n",
    "# yellow -> Y\n",
    "B_list = ['blue', 'purple', 'navy']\n",
    "C_list = ['green', 'olive', 'lime']\n",
    "R_list = ['red', 'pink', 'orange']\n",
    "Y_list = ['yellow', 'brown', 'tan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the color word in the command\n",
    "# but keep it map to the same expression\n",
    "exp_src_list = [src for src in raw_src_list]\n",
    "exp_tar_list = [tar for tar in raw_tar_list]\n",
    "for src, tar in zip(raw_src_list, raw_tar_list):\n",
    "    for b in B_list:\n",
    "        if b in src.split():\n",
    "            for color in B_list:\n",
    "                if b != color:\n",
    "                    new_src = src.replace(b, color)\n",
    "                    exp_src_list.append(new_src)\n",
    "                    exp_tar_list.append(tar)\n",
    "    for r in R_list:\n",
    "        if r in src.split():\n",
    "            for color in R_list:\n",
    "                if r != color:\n",
    "                    new_src = src.replace(r, color)\n",
    "                    exp_src_list.append(new_src)\n",
    "                    exp_tar_list.append(tar)\n",
    "    for y in Y_list:\n",
    "        if y in src.split():\n",
    "            for color in Y_list:\n",
    "                if y != color:\n",
    "                    new_src = src.replace(y, color)\n",
    "                    exp_src_list.append(new_src)\n",
    "                    exp_tar_list.append(tar)\n",
    "    for c in C_list:\n",
    "        if c in src.split():\n",
    "            for color in C_list:\n",
    "                if c != color:\n",
    "                    new_src = src.replace(c, color)\n",
    "                    exp_src_list.append(new_src)\n",
    "                    exp_tar_list.append(tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate\n",
    "new_src_list, new_tar_list = [], []\n",
    "for src, tar in zip(exp_src_list, exp_tar_list):\n",
    "    if src not in new_src_list:\n",
    "        new_src_list.append(src)\n",
    "        new_tar_list.append(tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CECW souze data size: 11153\n",
      "CECW target data size: 11153\n"
     ]
    }
   ],
   "source": [
    "print('CECW souze data size:', len(new_src_list))\n",
    "print('CECW target data size:', len(new_tar_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command: move to the large blue room while avoiding the small lime room\n",
      "expression: & F B G ! C\n"
     ]
    }
   ],
   "source": [
    "# take a look\n",
    "new_data_size = len(new_src_list)\n",
    "index = random.choice(range(new_data_size))\n",
    "print('command:', new_src_list[index])\n",
    "print('expression:', new_tar_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CECW training size: 8922\n",
      "CECW test size 2231\n"
     ]
    }
   ],
   "source": [
    "# 20% for training\n",
    "# 80% for test\n",
    "train_test_rate = 0.8\n",
    "index = np.random.permutation(new_data_size)\n",
    "index_list = np.split(index, [int(train_test_rate*new_data_size), new_data_size])\n",
    "train_index, test_index = index_list[0], index_list[1]\n",
    "print('CECW training size:', len(train_index))\n",
    "print('CECW test size', len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train_src_list = np.asarray(new_src_list)[train_index].tolist()\n",
    "train_tar_list = np.asarray(new_tar_list)[train_index].tolist()\n",
    "test_src_list = np.asarray(new_src_list)[test_index].tolist()\n",
    "test_tar_list = np.asarray(new_tar_list)[test_index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output as .txt files\n",
    "save_txt(TRAIN_SRC_PATH, train_src_list)\n",
    "save_txt(TRAIN_TAR_PATH, train_tar_list)\n",
    "save_txt(TEST_SRC_PATH, test_src_list)\n",
    "save_txt(TEST_TAR_PATH, test_tar_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
